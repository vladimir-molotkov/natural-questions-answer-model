# Постановка задачи
В данном репозитории создана модель, отвечающая на вопросы по естественнонаучным дисциплинам по информации из Википедии.
Производится сравнение BERT и GPT2 на тестовой выборке, затем модель GPT2 дообучается для повышения качества.

### Формат входных и выходных данных
Данные представлены в текстовом формате (файлы формата parquet) в виде пар "вопрос-ответ". В датасете представлены короткие и длинные ответы, в данном репозитории используются только короткие ответы.

### Метрика
В качестве метрики качества модели выбрана F1-мера по совпадению токенов. В данном случае требуется получить метрики выше бейзлайна BERT.

### Валидация
Датасет представлен в виде обучающей и валидационной выборки:
- Обучающая выборка состоит 307 тысяч примеров.
- Валидационная выборка фиксирована и состоит из 7 тысяч примеров.

### Данные
В данной работе используется датасет [Natural Questions](https://huggingface.co/datasets/google-research-datasets/natural_questions) от Google Research.
Датасет содержит выборку реальных вопросов из поисковой системы Google по естественным наукам с соответствующими ответами из топ-5 страниц Википедии и ссылками на источники. Ответы разделены на короткие и длинные. Для обучения модели отобраны пары "вопрос-ответ" только с короткими ответами.

### Бейзлайн
В качестве бейзлайн модели используется BERT.

### Основная модель
В качестве основной модели для дообучения предполагается использовать GPT-2.

### Внедрение
Модель может быть использована в качестве простого чат-бота для ответа на вопросы по естестенным науками. Кроме того, модель не требует значительных ресурсов для запуска.

# Setup
1. Клонируйте репозиторий
   ```bash
   git clone https://github.com/vladimir-molotkov/natural-questions-answer-model.git
   cd natural-questions-answer-model
   ```
3. Установите Poetry. Убедитесь, что у вас установлен `poetry`. Если нет, установите его:
   ```bash
   # Linux/macOS
   curl -sSL https://install.python-poetry.org | python3 -
   # Windows (PowerShell)
   (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -
   ```
4. Установите зависимости. В директории проекта выполните:
   ```bash
   poetry install
   ```
5. Активируйте виртуальное окружение
   ```bash
   poetry env activate
   ```
6. Загрузите датасет
   ```bash
   dvc pull
   ```
7. Запуск эксперимента. После активации окружения выполните:
   ```bash
   python main.py
   ```
   Если не активировали окружение в п.4, используйте:
   ```bash
   poetry run python main.py
   ```

# Train
При запуске `main.py` без параметров происходит сравнение BERT и GPT2 на тестовой выборке, затем происходит обучение GPT2. Если нужно запустить сразу обучение, то можно запустить с параметром benchmark False
```bash
main.py --benchmark False
```
Или можно изменить соответствующий параметр в конфигурации Hydra (configs/config.yaml)

# Inference
Для запуска модели представлен файл `inference.py`, в котором модель можно запустить для ответа на один вопрос (флаг single) или в формате чат-бота (interactive). В параметре checkpoint_path передается путь до обученной модели. Если его пропустить, то будет использована модель GPT2 с Hugging Face. Для выбора устройства torch используется параметр device (mps, cpu, cuda). Пример использования модели для ответа на один вопрос:
```bash
inference.py single ask --question "What is Data Science?"
```
Пример запуска модели в интерактивном режиме и выборе устройства mps:
```bash
inference.py interactive \
    --checkpoint_path "lightning_logs/version_0/checkpoints/epoch=2-step=100.ckpt" \
    --device "mps"
```

